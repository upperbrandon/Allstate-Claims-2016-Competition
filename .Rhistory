) +
theme_minimal(base_size = 14)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(alpha = 0.5, color = "darkorange") +
geom_text(vjust = -1, size = 3) +
scale_size(range = c(5, 15)) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
) +
theme_minimal(base_size = 14)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(alpha = 0.5, color = "darkorange") +
geom_text(vjust = -1, size = 3) +
scale_size(range = c(5, 15)) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(alpha = 0.5, color = "darkorange") +
geom_text(vjust = -1, size = 3) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(color = "darkorange") +
geom_text(vjust = -1, size = 3) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(color = "darkorange") +
geom_text(vjust = -1, size = 5) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
)
# Data
schools <- data.frame(
School = c("Rice", "MIT", "BYU", "Standford", "Cornell", "University of Texas"),
Tuition = c(76073, 89000, 15992, 85755, 86596, 55196),
Placement = c(72.2, 88.9, 87, 88, 81, 86)
)
# Scatter plot with color gradient
ggplot(schools, aes(x = Tuition, y = Placement, label = School, color = Placement)) +
geom_point(size = 6, alpha = 0.8) +
geom_text(vjust = -1, size = 4) +
scale_x_continuous(labels = comma) +
scale_color_gradient(low = "orange", high = "darkgreen") +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
color = "Placement %"
) +
theme_minimal(base_size = 14)
# Scatter plot with color gradient
ggplot(schools, aes(x = Tuition, y = Placement, label = School, color = Placement)) +
geom_point(size = 6, alpha = 0.8) +
geom_text(vjust = -1, size = 4) +
scale_x_continuous(labels = comma) +
scale_color_gradient(low = "white", high = "blue") +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
color = "Placement %"
) +
theme_minimal(base_size = 14)
# Scatter plot with color gradient
ggplot(schools, aes(x = Tuition, y = Placement, label = School, color = Placement)) +
geom_point(size = 6, alpha = 0.8) +
geom_text(vjust = -1, size = 4) +
scale_x_continuous(labels = comma) +
scale_color_gradient(low = "grey", high = "blue") +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
color = "Placement %"
) +
theme_minimal(base_size = 14)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(color = "darkorange") +
geom_text(vjust = -1, size = 5) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
)
# Bubble chart with larger x and y range
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(color = "darkorange", size = 6) +
geom_text(vjust = -1, size = 5) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
) +
xlim(0, 100000) +     # increase x-axis range
ylim(60, 100) +       # increase y-axis range
theme_minimal(base_size = 14)
library(ggplot2)
library(scales)
# Data
schools <- data.frame(
School = c("Rice", "MIT", "BYU", "SF", "Cornell", "University of Texas"),
Tuition = c(76073, 89000, 15992, 85755, 86596, 55196),
Placement = c(72.2, 88.9, 87, 88, 81, 86)
)
# Bubble chart with larger x and y range
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(color = "darkorange", size = 6) +
geom_text(vjust = -1, size = 5) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
) +
xlim(0, 100000) +     # increase x-axis range
ylim(60, 100) +       # increase y-axis range
theme_minimal(base_size = 14)
# Load libraries
library(ggplot2)
library(scales)  # for comma formatting
# Create data frame
schools <- data.frame(
School = c("Rice", "MIT", "BYU", "Standford", "Cornell", "University of Texas"),
Tuition = c(76073, 89000, 15992, 85755, 86596, 55196),
Placement = c(72.2, 88.9, 87, 88, 81, 86)
)
# Plot
ggplot(schools, aes(x = reorder(School, -Tuition))) +
geom_bar(aes(y = Tuition/1000), stat = "identity", fill = "skyblue") +
geom_line(aes(y = Placement*10, group = 1), color = "red", size = 1.5) +
geom_point(aes(y = Placement*10), color = "red", size = 3) +
scale_y_continuous(
name = "Tuition (in $1000s)",
sec.axis = sec_axis(~./10, name = "Placement (%)")
) +
labs(
x = "School",
title = "Tuition vs Placement Percentage by School"
) +
theme_minimal(base_size = 14) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(ggplot2)
library(scales)
# Data
schools <- data.frame(
School = c("Rice", "MIT", "BYU", "Standford", "Cornell", "University of Texas"),
Tuition = c(76073, 89000, 15992, 85755, 86596, 55196),
Placement = c(72.2, 88.9, 87, 88, 81, 86)
)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, size = Tuition, label = School)) +
geom_point(alpha = 0.6, color = "steelblue") +
geom_text(vjust = -1, size = 4) +
scale_x_continuous(labels = comma) +
scale_size(range = c(5, 15)) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
) +
theme_minimal(base_size = 14)
library(ggplot2)
library(scales)
# Data
schools <- data.frame(
School = c("Rice", "MIT", "BYU", "Standford", "Cornell", "University of Texas"),
Tuition = c(76073, 89000, 15992, 85755, 86596, 55196),
Placement = c(72.2, 88.9, 87, 88, 81, 86)
)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, size = Tuition, label = School)) +
geom_point(alpha = 0.6, color = "orange") +
geom_text(vjust = -1, size = 4) +
scale_x_continuous(labels = comma) +
scale_size(range = c(5, 15)) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
) +
theme_minimal(base_size = 14)
library(ggplot2)
library(scales)
# Data
schools <- data.frame(
School = c("Rice", "MIT", "BYU", "Standford", "Cornell", "University of Texas"),
Tuition = c(76073, 89000, 15992, 85755, 86596, 55196),
Placement = c(72.2, 88.9, 87, 88, 81, 86)
)
# Bubble chart
ggplot(schools, aes(x = Tuition, y = Placement, size = Tuition, label = School)) +
geom_point(alpha = 0.6, color = "orange") +
geom_text(vjust = -1, size = 4) +
scale_x_continuous(labels = comma) +
scale_size(range = c(5, 15)) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
) +
xlim(0, 100000) +     # increase x-axis range
ylim(60, 100) +
theme_minimal(base_size = 14)
library(ggplot2)
library(ggrepel)
# Bubble chart with non-overlapping labels
ggplot(schools, aes(x = Tuition, y = Placement, label = School)) +
geom_point(color = "darkorange", size = 6) +
geom_text_repel(size = 5, box.padding = 0.5, point.padding = 0.5) +
labs(
x = "Tuition ($)",
y = "Placement (%)",
title = "School Tuition vs Placement Percentage",
size = "Tuition"
) +
xlim(0, 100000) +
ylim(60, 100) +
theme_minimal(base_size = 14)
my_linear_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
library(tidyverse)
library(tidymodels)
library(vroom)
library(skimr)
library(DataExplorer)
library(patchwork)
library(glmnet)
library(ranger)
library(ggmosaic)
library(embed)
library(tensorflow)
library(themis)
set.seed(1213)
setwd("~/GitHub/Allstate-Claims-2016-Competition")
Train <- vroom("train.csv")
Test <- vroom("test.csv")
my_recipe <- recipe(loss ~ ., data = Train) %>%
step_mutate_at(all_numeric_predictors(), fn = as.factor) %>%
step_other(all_nominal_predictors(), threshold = 0.001) %>%
step_lencode(all_nominal_predictors(), outcome = vars(loss), smooth = FALSE) %>%
step_zv(all_predictors())
my_linear_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_linear_model) %>%
fit(data = Train)
lin_preds <- predict(bike_workflow, new_data = Test)
kaggle_submission <- lin_preds %>%
bind_cols(.,test_data) %>%
vroom_write(x = kaggle_submission, file = "./LinearPreds.csv", delim = ",")
kaggle_submission <- lin_preds %>%
bind_cols(.,test_data) %>%
vroom_write(x = kaggle_submission, file = "./LinearPreds.csv", delim = ",")
kaggle_submission <- lin_preds %>%
bind_cols(.,test_data)
kaggle_submission <- lin_preds %>%
bind_cols(.,Test)
vroom_write(x = kaggle_submission, file = "./LinearPreds.csv", delim = ",")
kaggle_submission <- lin_preds %>%
bind_cols(.pred,Test)
loss
lin_preds
kaggle_submission <- Test %>%
select(id) %>%
bind_cols(rf_predictions)
kaggle_submission <- Test %>%
select(id) %>%
bind_cols(lin_preds)
vroom_write(x = kaggle_submission, file = "./LinearPreds.csv", delim = ",")
kaggle_submission <- Test %>%
select(id) %>%
bind_cols(.pred)
lin_preds
kaggle_submission <- Test %>%
select(id)
vroom_write(x = kaggle_submission, file = "./LinearPreds.csv", delim = ",")
my_linear_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
bike_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_linear_model) %>%
fit(data = Train)
my_linear_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
Linear_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_linear_model) %>%
fit(data = Train)
lin_preds <- predict(Linear_workflow, new_data = Test)
kaggle_submission <- lin_preds %>%
select(id)
kaggle_rf_submission <- Test %>%
select(id) %>%
bind_cols(rf_predictions)
kaggle_submission_lm <- Test %>%
select(id) %>%
bind_cols(rf_predictions)
kaggle_submission_lm <- Test %>%
select(id) %>%
bind_cols(lin_preds)
vroom_write(x = kaggle_submission_lm, file = "./LinearPreds.csv", delim = ",")
lin_preds
Test
View(Test)
Test$id
lin_preds <- predict(Linear_workflow, new_data = Test) %>%
rename(loss = .pred)
kaggle_submission_lm <- Test %>%
select(id) %>%
bind_cols(lin_preds)
vroom_write(x = kaggle_submission_lm, file = "./LinearPreds.csv", delim = ",")
# Allstate < 1240
# Libraries ---------------------------------------------------------------
library(tidyverse)
library(tidymodels)
library(vroom)
library(skimr)
library(DataExplorer)
library(patchwork)
library(glmnet)
library(ranger)
library(ggmosaic)
library(embed)
library(tensorflow)
library(themis)
set.seed(1213)
# WD ----------------------------------------------------------------------
setwd("~/GitHub/Allstate-Claims-2016-Competition")
# Read Files --------------------------------------------------------------
Train <- vroom("train.csv")
Test <- vroom("test.csv")
# Recipe ------------------------------------------------------------------
my_recipe <- recipe(loss ~ ., data = Train) %>%
step_mutate_at(all_numeric_predictors(), fn = as.factor) %>%
step_other(all_nominal_predictors(), threshold = 0.001) %>%
step_lencode(all_nominal_predictors(), outcome = vars(loss), smooth = FALSE) %>%
step_zv(all_predictors())
# Model -------------------------------------------------------------------
rf_mod <- rand_forest(
mtry  = tune(),
min_n = tune(),
trees = 100
) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("regression")
rf_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rf_mod)
folds <- vfold_cv(Train, v = 2, strata = loss)
rf_grid <- grid_regular(
mtry(range = c(1, 6)),
min_n(range = c(5, 25)),
levels = 2
)
rf_tuned <- tune_grid(
rf_wf,
resamples = folds,
grid = rf_grid,
metrics = metric_set(rmse)
)
rf_best <- select_best(rf_tuned, metric = "rmse")
rf_final_wf <- finalize_workflow(rf_wf, rf_best)
rf_final_fit <- fit(rf_final_wf, data = Train)
rf_predictions <- predict(rf_final_fit, new_data = Test, type = "numeric") %>%
rename(loss = .pred)
kaggle_rf_submission <- Test %>%
select(id) %>%
bind_cols(rf_predictions)
vroom_write(
kaggle_rf_submission,
file = "./Forest.csv",
delim = ","
)
# 50 trees Score 1228.259 (Nothing)
# 100 trees Score 1226.30 (Seed 1213)
# 100 trees Score
# Linear Model ------------------------------------------------------------
my_linear_model <- linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
Linear_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(my_linear_model) %>%
fit(data = Train)
lin_preds <- predict(Linear_workflow, new_data = Test) %>%
rename(loss = .pred)
kaggle_submission_lm <- Test %>%
select(id) %>%
bind_cols(lin_preds)
vroom_write(x = kaggle_submission_lm, file = "./LinearPreds.csv", delim = ",")
# EDA ---------------------------------------------------------------------
# Searching columns for Dep variable
colnames(Train)
pull(Train,loss)
b <- -Inf  # start with the smallest possible number
for (i in 1:14) {
a <- paste0("cont", i)
col_max <- max(Train[[a]], na.rm = TRUE)
if (col_max > b) {
b <- col_max
}
}
b
boost_model <- boost_tree(tree_depth = tune(),
trees = tune(),
learn_rate = tune()) %>%
set_engine("lightgbm") %>%
set_mode("regression")
library(bonsai)
library(lightgbm)
library(tensorflow)
library(themis)
boost_workflow <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(boost_model)
folds <- vfold_cv(Train, v = 2, repeats=1)
grid_of_tuning_params <- grid_regular(
tree_depth(range = c(1, 10)),
learn_rate(range = c(-3, -0.1)),
trees(range = c(10, 50)),
levels = 2
)
CV_results <- boost_workflow %>%
tune_grid(resamples=folds,
grid=grid_of_tuning_params,
metrics=metric_set(rmse, mae))
collect_metrics(CV_results) %>%
filter(.metric=="rmse") %>%
ggplot(data=., aes(x=penalty, y=mean, color=factor(mixture))) +
geom_line()
bestTune <- CV_results %>%
select_best(metric="rmse")
final_wf <-
boost_workflow %>%
finalize_workflow(bestTune) %>%
fit(data=Train)
boost_preds <- predict(final_wf, new_data = Test) %>%
rename(loss = .pred)
kaggle_submission_lm <- Test %>%
select(id) %>%
bind_cols(boost_preds)
vroom_write(x = kaggle_submission_lm, file = "./BoostPreds.csv", delim = ",")
rf_mod <- rand_forest(
mtry  = tune(),
min_n = tune(),
trees = 100
) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("regression")
rf_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rf_mod)
folds <- vfold_cv(Train, v = 2, strata = loss)
rf_grid <- grid_regular(
mtry(range = c(1, 6)),
min_n(range = c(5, 25)),
levels = 2
)
rf_tuned <- tune_grid(
rf_wf,
resamples = folds,
grid = rf_grid,
metrics = metric_set(mae)
)
rf_best <- select_best(rf_tuned, metric = "mae")
rf_final_wf <- finalize_workflow(rf_wf, rf_best)
rf_final_fit <- fit(rf_final_wf, data = Train)
rf_predictions <- predict(rf_final_fit, new_data = Test, type = "numeric") %>%
rename(loss = .pred)
kaggle_rf_submission <- Test %>%
select(id) %>%
bind_cols(rf_predictions)
vroom_write(
kaggle_rf_submission,
file = "./Forest.csv",
delim = ","
)
